#!/usr/bin/env python3
"""
ä¿®å¤ç‰ˆ Token æ”¶é›†å™¨
æ”¯æŒå¤š session è·Ÿè¸ªå’Œå®Œæ•´å†å²æ•°æ®æå–
"""

import json
import os
import sys
from pathlib import Path
from datetime import datetime, timezone
from typing import Dict, List, Set, Optional

class TokenExtractor:
    def __init__(self):
        self.workspace = Path("/root/.openclaw/workspace")
        self.sessions_dir = Path("/root/.openclaw/agents/main/sessions")
        self.memory_dir = self.workspace / "memory"
        self.tracker_file = self.memory_dir / "token-logger-tracker.json"
        self.token_log = self.memory_dir / "token-usage.jsonl"
        
        self.memory_dir.mkdir(parents=True, exist_ok=True)
        
    def load_tracker(self) -> Set[str]:
        """åŠ è½½å·²è®°å½•çš„æ—¶é—´æˆ³"""
        try:
            with open(self.tracker_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return set(data.get('loggedTimestamps', []))
        except (FileNotFoundError, json.JSONDecodeError):
            return set()
    
    def save_tracker(self, logged_timestamps: Set[str]):
        """ä¿å­˜å·²è®°å½•çš„æ—¶é—´æˆ³"""
        data = {
            'loggedTimestamps': list(logged_timestamps),
            'lastUpdated': datetime.now(timezone.utc).isoformat(),
            'totalEntries': len(logged_timestamps)
        }
        with open(self.tracker_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    
    def load_sessions_config(self) -> Dict:
        """åŠ è½½ sessions é…ç½®"""
        sessions_index = self.sessions_dir / "sessions.json"
        if not sessions_index.exists():
            return {}
        
        with open(sessions_index, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def extract_token_data_from_session(self, session_file: Path) -> List[Dict]:
        """ä» session æ–‡ä»¶æå–æ‰€æœ‰æœªè®°å½•çš„ token æ•°æ®"""
        if not session_file.exists():
            return []
        
        token_data_list = []
        logged_timestamps = self.load_tracker()
        
        try:
            with open(session_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    
                    try:
                        entry = json.loads(line)
                        if self._is_valid_token_entry(entry):
                            token_data = self._extract_token_info(entry)
                            if token_data['timestamp'] not in logged_timestamps:
                                token_data_list.append(token_data)
                    except json.JSONDecodeError:
                        continue
        except Exception as e:
            print(f"[ERROR] è¯»å–æ–‡ä»¶ {session_file} æ—¶å‡ºé”™: {e}")
        
        return token_data_list
    
    def _is_valid_token_entry(self, entry) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ token æ¡ç›®"""
        if entry.get('type') != 'message':
            return False
        
        message = entry.get('message', {})
        if message.get('role') != 'assistant':
            return False
        
        usage = message.get('usage', {})
        if not usage:
            return False
        
        total_tokens = usage.get('totalTokens', 0)
        if total_tokens <= 0:
            return False
        
        return True
    
    def _extract_token_info(self, entry) -> Dict:
        """æå– token ä¿¡æ¯"""
        message = entry['message']
        usage = message['usage']
        
        return {
            'timestamp': entry.get('timestamp'),
            'date': entry.get('timestamp', '').split('T')[0],
            'provider': message.get('provider', 'unknown'),
            'model': message.get('model', 'unknown'),
            'input': usage.get('input', 0),
            'output': usage.get('output', 0),
            'cacheRead': usage.get('cacheRead', 0),
            'cacheWrite': usage.get('cacheWrite', 0),
            'totalTokens': usage.get('totalTokens', 0),
            'cost': {
                'input': usage.get('cost', {}).get('input', 0),
                'output': usage.get('cost', {}).get('output', 0),
                'cacheRead': usage.get('cost', {}).get('cacheRead', 0),
                'cacheWrite': usage.get('cost', {}).get('cacheWrite', 0),
                'total': usage.get('cost', {}).get('total', 0),
            }
        }
    
    def append_to_log(self, token_data_list: List[Dict]) -> int:
        """å°† token æ•°æ®è¿½åŠ åˆ°æ—¥å¿—æ–‡ä»¶"""
        if not token_data_list:
            return 0
        
        new_count = 0
        try:
            with open(self.token_log, 'a', encoding='utf-8') as f:
                for token_data in token_data_list:
                    f.write(json.dumps(token_data) + '\n')
                    new_count += 1
        except Exception as e:
            print(f"[ERROR] å†™å…¥ token æ—¥å¿—æ—¶å‡ºé”™: {e}")
            return 0
        
        return new_count
    
    def extract_all_sessions(self) -> Dict:
        """æå–æ‰€æœ‰ session çš„ token æ•°æ®"""
        print("[TOKEN-EXTRACT] å¼€å§‹æå–æ‰€æœ‰ sessions çš„ token æ•°æ®...")
        
        sessions_config = self.load_sessions_config()
        if not sessions_config:
            print("[TOKEN-EXTRACT] âŒ æœªæ‰¾åˆ° sessions é…ç½®")
            return {"success": False, "message": "sessions config not found"}
        
        total_new_entries = 0
        sessions_processed = 0
        session_details = []
        
        # å¤„ç†æ‰€æœ‰ session
        for session_key, session_info in sessions_config.items():
            session_file = session_info.get('sessionFile')
            if not session_file:
                continue
            
            session_file_path = Path(session_file)
            if not session_file_path.exists():
                continue
            
            sessions_processed += 1
            print(f"[TOKEN-EXTRACT] å¤„ç† session: {session_key} -> {session_file_path}")
            
            # æå– token æ•°æ®
            token_data_list = self.extract_token_data_from_session(session_file_path)
            new_entries = len(token_data_list)
            
            if new_entries > 0:
                # è¿½åŠ åˆ°æ—¥å¿—
                added = self.append_to_log(token_data_list)
                total_new_entries += added
                
                session_details.append({
                    'session_key': session_key,
                    'session_file': str(session_file_path),
                    'new_entries': added,
                    'file_size': session_file_path.stat().st_size if session_file_path.exists() else 0
                })
                
                print(f"[TOKEN-EXTRACT] âœ… {session_key}: æ–°å¢ {added} æ¡è®°å½•")
            else:
                print(f"[TOKEN-EXTRACT] â­ï¸ {session_key}: æ— æ–°æ•°æ®")
        
        # æ›´æ–° tracker
        all_logged = self.load_tracker()
        for session_detail in session_details:
            for token_data in self.extract_token_data_from_session(Path(session_detail['session_file'])):
                all_logged.add(token_data['timestamp'])
        
        self.save_tracker(all_logged)
        
        result = {
            "success": True,
            "message": "Extraction completed",
            "sessions_processed": sessions_processed,
            "total_new_entries": total_new_entries,
            "session_details": session_details,
            "tracker_updated": len(all_logged)
        }
        
        print(f"[TOKEN-EXTRACT] ğŸ“Š å¤„ç†äº† {sessions_processed} ä¸ª sessions")
        print(f"[TOKEN-EXTRACT] ğŸ“ˆ æ–°å¢ {total_new_entries} æ¡ token è®°å½•")
        print(f"[TOKEN-EXTRACT] ğŸ“ Tracker ç°åœ¨æœ‰ {len(all_logged)} æ¡è®°å½•")
        
        return result
    
    def run_extraction(self) -> int:
        """è¿è¡Œæå–ä»»åŠ¡ï¼Œè¿”å›çŠ¶æ€ç """
        try:
            result = self.extract_all_sessions()
            return 0 if result.get("success", False) else 1
        except Exception as e:
            print(f"[TOKEN-EXTRACT] âŒ æå–è¿‡ç¨‹å‡ºé”™: {e}")
            return 1

def main():
    extractor = TokenExtractor()
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        if command == "extract":
            sys.exit(extractor.run_extraction())
        elif command == "status":
            print(f"Sessions dir: {extractor.sessions_dir}")
            print(f"Token log: {extractor.token_log}")
            print(f"Tracker file: {extractor.tracker_file}")
            
            if extractor.token_log.exists():
                with open(extractor.token_log, 'r', encoding='utf-8') as f:
                    total_entries = sum(1 for _ in f)
                print(f"Total logged entries: {total_entries}")
            else:
                print("Total logged entries: 0")
            
            if extractor.tracker_file.exists():
                with open(extractor.tracker_file, 'r', encoding='utf-8') as f:
                    tracker_data = json.load(f)
                print(f"Tracker entries: {tracker_data.get('totalEntries', 0)}")
            else:
                print("Tracker entries: 0")
        else:
            print(f"Usage: {sys.argv[0]} {{extract|status}}")
            sys.exit(1)
    else:
        # é»˜è®¤æ‰§è¡Œæå–
        sys.exit(extractor.run_extraction())

if __name__ == "__main__":
    main()